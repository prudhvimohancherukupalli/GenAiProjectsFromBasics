{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3cbf42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ\")\n",
    "\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31993b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"llama-3.1-8b-instant\",groq_api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51acd1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to meet you, Prudhvi. I'm happy to help you learn and explore the world of GenAI (Generative Artificial Intelligence). It's a rapidly evolving field with many exciting applications in software development, natural language processing, and more.\n",
      "\n",
      "What specific aspects of GenAI would you like to learn about or discuss? Are you interested in:\n",
      "\n",
      "1. Text-to-text or text-to-image models?\n",
      "2. Model architecture (e.g., transformers, recurrent neural networks)?\n",
      "3. Data preprocessing and generation techniques?\n",
      "4. Applications of GenAI in software development (e.g., code generation, chatbots)?\n",
      "5. Something else?\n",
      "\n",
      "Let me know, and I'll do my best to assist you in your learning journey, Prudhvi.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([\n",
    "    HumanMessage(content=\"Hi, my name is Prudhvi. I'm a software developer learning GenAI.\")\n",
    "])\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0bea2",
   "metadata": {},
   "source": [
    "#### Message History\n",
    "\n",
    "\n",
    "We can use a Message History class to wrap our model and make it statefull.This will keep track of inputs and outputs of the model and store them in some datastore. Fututre intecrations will then load those messages and pss them into the chain as part of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56bdfb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:id) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90030ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name is Prudhvi. I'm a software developer learning GenAI.\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5c740a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Prudhvi, nice to meet you. Learning GenAI (Generative AI) can be a fascinating and rewarding field. GenAI involves the development of algorithms and models that can generate new, original content, such as text, images, music, or even entire stories.\\n\\nWhat specific aspects of GenAI are you interested in learning? Are you looking at text generation, image generation, or perhaps something else?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9a12556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Prudhvi, and you're trying to learn about GenAI (Generative AI).\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name and iam trying to learn\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adcd12ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have any information about your name. I'm a conversational AI, and this is the beginning of our conversation. I don't store personal data, so I won't be able to recall your name if you don't tell me. If you'd like to share your name, I'm happy to chat with you!\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### what if we change the session id\n",
    "## change the config-->session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd2b492",
   "metadata": {},
   "source": [
    "#### Prompt templates\n",
    "\n",
    "promt template help to turn raw user inforamtion into a formate that the LLM can work with. in this case the raw user input is just a mesage which weare passiong to LLm let now make that a bit more complicated. \n",
    "\n",
    "First add in a sustem messsage with some cistom instructions we will add in more inputs besides just the messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "912d0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Amnswer all the question to the nest of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0fa7620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Prudhvi, it's nice to meet you. I'm here to assist you with any questions or information you may need. What's on your mind today? Do you have a specific topic or issue you'd like to discuss?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 59, 'total_tokens': 109, 'completion_time': 0.059819112, 'completion_tokens_details': None, 'prompt_time': 0.003091247, 'prompt_tokens_details': None, 'queue_time': 0.005378352, 'total_time': 0.062910359}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9ca2574dca', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b8875-6324-71e2-bf0a-c9fa93d75a43-0', usage_metadata={'input_tokens': 59, 'output_tokens': 50, 'total_tokens': 109})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name prudhvi\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3aff7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history2=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76fba635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Prudhvi. It's nice to meet you. Is there something I can help you with today?\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history2.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is prudhvi\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e06a92af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Prudhvi.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history2.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b05dab",
   "metadata": {},
   "source": [
    "#### Managing the conversation History\n",
    "\n",
    "One importatnt concept to understand when building chatbot is how to manage conversation history. if left unmanged the list of messages will grow unbounded and potentially overflow the context window of the LLM. Thereefore it is importatnt to add a step that limits the size of the messages you are passing in. trim_messages to reduce how many messages we are sending to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef118f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
